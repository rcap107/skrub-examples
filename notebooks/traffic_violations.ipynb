{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import skrub\n",
    "\n",
    "from skrub import TableReport, Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf59e02",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data = skrub.datasets.fetch_traffic_violations().traffic_violations\n",
    "data = pl.from_pandas(data.sample(10000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable contains 4 distinct values, but we will treat it as a\n",
    "# binary classification problem by dropping the two least frequent classes.\n",
    "data = data.filter(~pl.col(\"violation_type\").is_in([\"SERO\", \"ESERO\"]))\n",
    "# We first convert X and y into skrub expressions.\n",
    "X = skrub.var(\"data\", data.drop(\"violation_type\")).skb.mark_as_X()\n",
    "y = skrub.var(\"target\", data[\"violation_type\"]).skb.mark_as_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0753ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert columns that contain dates and drop uninformative columns using the Cleaner.\n",
    "c = Cleaner(drop_null_fraction=0.9, drop_if_constant=True)\n",
    "\n",
    "X_ = (\n",
    "    X.with_columns(pl.col(\"date_of_stop\") + \" \" + pl.col(\"time_of_stop\"))\n",
    "    .drop(\"time_of_stop\")   \n",
    "    .skb.apply(c)\n",
    ")\n",
    "X_ = X_.sort(\"date_of_stop\", descending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub.selectors as s\n",
    "\n",
    "# Create a column selector with arbitrary logic.\n",
    "binary = s.filter(lambda col: col.drop_nulls().n_unique() == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ac3d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_to_binary(df):\n",
    "    for col in df.columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).cast(pl.Categorical).cast(pl.Boolean, strict=False).alias(col)\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934713aa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "binary_cols = X_.skb.select(binary).skb.apply_func(convert_to_binary)\n",
    "\n",
    "converted = X_.skb.select(~binary).skb.concat([binary_cols], axis=1)\n",
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop more columnns that are not informative.\n",
    "preprocessed = converted.drop(\n",
    "    \"seqid\",\n",
    "    \"geolocation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use the skrub encoders to add new features to the table.\n",
    "from skrub import TableVectorizer, DatetimeEncoder, StringEncoder\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "cat_encoder = skrub.choose_from(\n",
    "    {\n",
    "        # \"target\": TargetEncoder(),\n",
    "        \"string\": StringEncoder(n_components=5),\n",
    "    },\n",
    "    name=\"cat_encoder\",\n",
    ")\n",
    "datetime_encoder = DatetimeEncoder(\n",
    "    resolution=\"day\",\n",
    "    add_weekday=True,\n",
    "    add_total_seconds=False,\n",
    "    periodic_encoding=skrub.choose_from(\n",
    "        [None, \"spline\", \"circular\"], name=\"periodic_encoding\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "num_encoder = skrub.choose_from(\n",
    "    {\n",
    "        \"kbins\": make_pipeline(\n",
    "            SimpleImputer(),\n",
    "            KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"quantile\"),\n",
    "        ),\n",
    "        \"passthrough\": make_pipeline(SimpleImputer()),\n",
    "    },\n",
    "    name=\"num_encoder\",\n",
    ")\n",
    "\n",
    "postprocess = make_pipeline(\n",
    "    SimpleImputer(),\n",
    ")\n",
    "\n",
    "high_cardinality = s.string() - s.cardinality_below(40)\n",
    "\n",
    "leftover = s.all() - s.any_date() - high_cardinality - s.numeric()\n",
    "\n",
    "dates = preprocessed.skb.select(cols=s.any_date()).skb.apply(datetime_encoder)\n",
    "strings = preprocessed.skb.select(cols=s.string() - s.cardinality_below(40)).skb.apply(\n",
    "    cat_encoder,\n",
    ")\n",
    "numbers = preprocessed.skb.select(cols=s.numeric()).skb.apply(\n",
    "    num_encoder, \n",
    ")\n",
    "\n",
    "everything_else = preprocessed.skb.select(\n",
    "    cols=leftover\n",
    ").skb.apply(TableVectorizer(), cols=leftover).skb.apply(postprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a10254",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "encoded = (\n",
    "    everything_else.skb.concat([dates, strings, numbers], axis=1)\n",
    ")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c86c0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "cv = TimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    max_train_size=None,\n",
    "    gap=0,\n",
    "    test_size=1000,\n",
    ")\n",
    "\n",
    "model = skrub.choose_from(\n",
    "    {\n",
    "        \"logistic\": LogisticRegression(max_iter=500,\n",
    "            # max_iter=skrub.choose_int(100, 1000, log=True, name=\"max_iter\"),\n",
    "            C=skrub.choose_float(0.5, 10, log=True, name=\"C\", n_steps=3),\n",
    "        ),\n",
    "        \"hgb\": HistGradientBoostingClassifier(\n",
    "            learning_rate=skrub.choose_float(0.01, 0.9, log=True, name=\"lr\")\n",
    "        ),\n",
    "    },\n",
    "    name=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58494081",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = encoded.skb.apply(model, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7af2c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "search = predicted.skb.get_randomized_search(\n",
    "    n_jobs=4, fitted=True, n_iter=32, random_state=1, scoring=\"roc_auc\", cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa7522",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "search.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd264305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
